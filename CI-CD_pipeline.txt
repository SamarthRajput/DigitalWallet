CI -> Continous Integration
CD -> Continous Deployment
as the name suggests are the process of continously integrating your code on github
In a repositry with so many people collaborating, it is a good idea ki every commit is checked and even before people commit, we should ki what every changes they have made are they following the code practices 
are the tests still running, is the code linted well 
Making sure ki before people push anything the maintainer can just run a workflow and see ki whatever changes they have made are they following a certain code practices or not 
CD is deploying it automatically from github to wherever you have hosted your codebase, so any time a commit is happening on the main branch, it automatically deploys to an EC2 instance lets say

We can do some optimisations in monorepo, ki if you are deploying your nextjs application, you do not have to build your merchant app or your express app if you are just deploying 1 app
if you have 3 applications and you are only deploying 1, you donot have to build the other 2 that is one optimisation you can do.
we can also add turbo build cache but we are not doing this 

Anytime someone is trying to merge into my repositry, create a pull request, I should run a workflow that makes sure, ki the code that they are pushing in is building correctly at the very least, there is no error in the code 
that is making the code not build, so for that you can add your very first CI pipeline 
Anytime someone creates a pull request, do a check and what to do inside the check both of these things need to be defined, somewhere in your repositry and if your are using github 
the place where they are defined is the .github folder 
Anytime you open a repositry and see a .github folder it means it has all of your workflows 
So if you ever create a folder called .github/workflows in your repositry and add a .yml file over there, it is very similar to the json file 

Anytime a pullrequest runs on any branch, then you should run this Continous Integration job, which will run on an ubuntu machine and 
1. Clone the repositry on that ubuntu machine, we usually use actions that other people have created, the actions helps us cloning the repo easily on the ubuntu machine 
and rests of the steps we are running ourselves.

As the repositry builds correctly now we need to make sure, anyone that is creating a pull request also after they changes, the repositry builds correctly
1st step: creating the yml file that you will push to github in the .github/workflows folder so that github knows it needs to runs a workflow
We give it a name, when should this run, it should run, whenever a pull request is made on any codebase but on the main or master branch we can give the name of the branch 
if someone creates a pull request to any different branch dont run this workflow, if someone creates a pull request on the main or master branch then run this workflow
we add more branches like master, dev 
Now the jobs that you have to run, we have to run a single a job, a build job, we can give it a name, runs-on and the steps you follow 
If your yml file is little malformed, your workflow wont run it will be very hard for you to debug, so make sure yml file is correctly linted 
the steps the yml file performs is, clones the repositry, installs nodejs on the machine, runs npm install and finally runs npm run build 
if npm run build succeeds then your pr will get a green tick, if not then it will fail 

Usually people add another workflow for checking whether or not the tests are succeeded, add another workflow for checking whether or not the coverage increases or remains the same 
if your test coverage, the number of files that you are testing are covering or number of lines of code your test are covering, if they go down the pull request gets fails 

Continous Deployment
firstly we dockerize our application, for that we need to create separate docker files for all 3 of these apps, we cannot create a single docker file for everyone and we cannot start 3 processes on different ports in a single docker file 
so you need to create multiple docker files 
General way to create is, create a root folder docker and inside this you add various dockerfiles 
to dockerize a nextjs application it is very similar to a nodejs application 

In the past, we used to copy over the files and then run npm install and then copy over the rest of the files, why are you copying over everything, and then running npm install ?
because we are using a monorepo, unfortunately if you are using a monorepo your apps folder will have there own package.json, your packages folder will have there own package.jsons, so you can write very complicated script 
first, bringing all package.jsons then running npm install and then copying the rests of the things, you probably should do it, bcz of the benefit to decrease the build time by pushing up the docker layers 
This is how we containerize our application
Building the docker file, 1st the dockerfile should be present in our root folder called Dockerfile 
We are copying ./docker/Dockerfile.user over to root folder in the .Dockerfile
command -> cp ./docker/Dockerfile.user ./Dockerfile, we will eventually delete the root .Dockerfile because we have multiple applications they will each have there own docker file, we donot want to put a singleone in the root folder 
so now we can run docker build command to build the image  
Building docker image command -> docker build -t name_of_image .
this will containerize my application, it will create an image for me that i can run locally without installing nodejs everything happens inside a container

Elastic beanstalk helps in autoscaling the application
ECR => Elastic container registry
ECS => Elastic container service  ->  lets you autoscale docker containers
ASG => autoscaling groups
GCP Cloud run => google cloud platform
Iac => Infrastructure as code